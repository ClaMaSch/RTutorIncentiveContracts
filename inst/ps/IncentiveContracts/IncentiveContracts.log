{"type":["init_ps"],"time":["2018-11-14 16:46:20"],"user":["default_user"],"umph":[1542210380.8551],"ok":[true]}
,
{"type":["init_ps"],"time":["2018-11-14 17:46:56"],"user":["default_user"],"umph":[1542214016.2748],"ok":[true]}
,
{"type":["init_ps"],"time":["2018-11-14 17:49:56"],"user":["default_user"],"umph":[1542214196.2339],"ok":[true]}
,
{"type":["init_ps"],"time":["2018-11-20 15:31:55"],"user":["default_user"],"umph":[1542724315.6895],"ok":[true]}
,
{"type":["check_chunk"],"time":["2018-11-20 15:32:39"],"user":["default_user"],"umph":[1542724359.8304],"ok":[false],"chunk":[42],"ex":[10],"e.ind":[0],"code":["center = c(-93.37,46.55)\nserpentlake = c(-93.927,46.480)\nproject = serpentlake\nmap_subsample(center,serpentlake)"],"message":["evaluation error in \n  map_subsample(center, serpentlake)\n  Error in download.file(url, destfile = destfile, quiet = !messaging, mode = \"wb\"): cannot open URL 'https://maps.googleapis.com/maps/api/staticmap?center=46.55,-93.37&zoom=7&size=640x640&scale=2&maptype=roadmap&language=en-EN'\n"]}
,
{"type":["init_ps"],"time":["2018-11-20 16:54:45"],"user":["default_user"],"umph":[1542729285.7203],"ok":[true]}
,
{"type":["init_ps"],"time":["2018-11-25 20:03:41"],"user":["default_user"],"umph":[1543172621.0497],"ok":[true]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:04:03"],"user":["default_user"],"umph":[1543172643.7854],"ok":[false],"chunk":[37],"ex":[8],"e.ind":[0],"code":["contracts = read.dta13(\"contracts.dta\")\nshock.estimation = read.csv2(\"shock.estimation.csv\") # saved within Ex.4\n\nplanned_days = contracts$planned_days\nactual_days = contracts$actual_days\ndw_norm = contracts$dw_norm\npenalty = contracts$penalty\npenalty_norm = contracts$penalty_norm\n\nN = nrow(contracts) # total number of observed contract\nenforcement = contracts$enforcement # observed enf. for late contracts\noutcome = contracts$outcome2 # contract outcome (further info in the appendix)\n\n# contractors information set (variables for the matrix X)\nones = rep(1,N) # constant\nshock = shock.estimation[,]\nplanned_workrate = contracts$planned_workrate\ncontrval_norm = contracts$contrval_norm\nrain = contracts$rain\nsnow = contracts$snow\nbig_firm = contracts$big_firm\ninstate = contracts$instate\nfirm_backlog_norm = contracts$firm_backlog_norm\noverlap = contracts$overlap\nX=cBind(ones,shock,planned_workrate,contrval_norm,rain,snow,big_firm,instate,firm_backlog_norm,overlap)\n\n# additional and saved penalties (delta's)\ndelta.plus = (actual_days+1-pmax(actual_days,planned_days))*penalty\ndelta.minus = (actual_days-pmax(actual_days-1,planned_days))*penalty\n# For outcomes that do not apply, the result is equal to zero.\ndelta.plus[outcome==\"early\"] = 0\ndelta.minus[outcome==\"early\"|outcome==\"ontime\"] = 0\n\n############################### FUNCTIONS ###############################\nloglikelihood = function(coefs){\n  # Since we `log-likelihood`, we use the exp()-function for the parameters\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2]) # alpha should be negative -> slope of -c'(d)\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  ll = rep(0,N)\n  \n  # early contract\n  ll[outcome==\"early\"] = log(pnorm(rb.noenforce[outcome==\"early\"]) - pnorm(lb.noenforce[outcome==\"early\"]))\n  # late contract  \n  ll[outcome==\"late\"&enforce==0] = log(pnorm(rb.noenforce[outcome==\"late\"&enforce==0]) - pnorm(lb.noenforce[outcome==\"late\"&enforce==0])) + log(1-mean(enforce))\n  ll[outcome==\"late\"&enforce==1] = log(pnorm(rb.enforce[outcome==\"late\"&enforce==1]) - pnorm(lb.enforce[outcome==\"late\"&enforce==1])) + log(mean(enforce))\n# ontime contract - expected loglikelihood depending on the current enforcement choice\n  ll[outcome==\"ontime\"] = enforce[outcome==\"ontime\"]*log(pnorm(rb.enforce[outcome==\"ontime\"]) - pnorm(lb.enforce[outcome==\"ontime\"])) + (1-enforce[outcome==\"ontime\"])*log(pnorm(rb.noenforce[outcome==\"ontime\"]) - pnorm(lb.noenforce[outcome==\"ontime\"]))\n  LL = sum(ll)\n  return(LL)\n}\n\nenforce.posterior = function(coefs){\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2])\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # Bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  p.hat = mean(enforce)\n  posterior = enforce\n  \n  posterior[outcome==\"early\"] = p.hat\n  posterior[outcome==\"late\"] = enforcement[outcome==\"late\"]\n  \n  l.enforce = pnorm(rb.enforce) - pnorm(lb.enforce)\n  l.noenforce = pnorm(rb.noenforce) - pnorm(lb.noenforce)\n  \n  posterior[outcome==\"ontime\"] = p.hat*l.enforce[outcome==\"ontime\"]/(p.hat*l.enforce[outcome==\"ontime\"] + (1-p.hat)*l.noenforce[outcome==\"ontime\"])\n  return(posterior)\n}\n\ny.calc = function(alpha){\n  y = rep(0,N)\n  y[outcome == \"early\"] = -alpha*dw_norm[outcome == \"early\"]\n  y[outcome == \"ontime\"] = -alpha*dw_norm[outcome == \"ontime\"]\n  y[outcome == \"late\"] =  -alpha*dw_norm[outcome == \"late\"] + enforce[outcome == \"late\"]*penalty_norm[outcome == \"late\"]\n  return(y)\n}\n#########################################################################\n\n## STARTVALUE STEPS\nenforce = rep(1,N)\nenforce[outcome==\"late\"] = enforcement[outcome==\"late\"]\nenforce[outcome==\"early\"] = mean(enforce)\n\nn.start = 2000 # number of start values\nsigma.start = rnorm(n.start)*10 # N(0,100) distributed\nalpha.start = rnorm(n.start)*10 # N(0,100) distributed\n\n# evaluate every fval for the 1000 sigma and alpha possibilities\nfval.start = rep(0,n.start)\nfor (i in 1:n.start) {\n  fval.start[i] = loglikelihood(c(sigma.start[i],alpha.start[i]))\n}\n\n# identify the decent start values\nindex.decent = which(fval.start > -Inf)\nsigma.decent = sigma.start[index.decent]\nalpha.decent = alpha.start[index.decent]\nfval.decent = fval.start[index.decent]\n\n# coefs combination which generates the max fval -> maximum loglikelihood\nindex.max = which(fval.decent == max(fval.decent))\nfval.max = fval.decent[index.max]\ncoefs.max= c(sigma.decent[index.max],alpha.decent[index.max])\n\n############################### PLOT ###############################\n# plot of the decent values (I used the dist. between the several sigma\n# and alpha values on the x-axis and the corresponding fval on the y-axis\nplot(abs(sigma.decent-alpha.decent),fval.decent)\n# zooming into the maximum location\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch = 20,col=\"red\")\n####################################################################\n\nnm_opti = optim(coefs.max,loglikelihood,control=list(fnscale=-1))\ncoefs.star = nm_opti$par\nfval.star = nm_opti$value\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=3)\n####################################################################\ncoefs1 = coefs.star\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8) {\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs1)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs1,loglikelihood,control=list(fnscale=-1))\n  coefs1 = nm_opti$par\n  fval1 = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\n# include new points\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n####################################################################\n\n## FINAL EM-ALGORITHM\nalpha.hat = -exp(coefs1[2])\ny = y.calc(alpha.hat)\nbeta.start = solve(t(X)%*%X)%*%t(X)%*%y\ncoefs = c(coefs1,beta.start)\nnm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\ncoefs = nm_opti$par\nfval = nm_opti$value\ncoefs2=coefs\nfval2=fval\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n# include new points\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8){\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\n  coefs = nm_opti$par\n  fval = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=4,lwd=2)\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n# include new points\npoints(abs(coefs[1]-coefs[2]),fval,pch=21,col=\"black\",bg=\"#299a20\",cex=2)\n######################### RESULTS #########################\nestimates = c(P.hat.current,exp(coefs[1]),-exp(coefs[2]),coefs[3:length(coefs)])\nestimates"],"message":["evaluation error in \n  shock.estimation = read.csv2(\"shock.estimation.csv\")\n  Error in file(file, \"rt\"): cannot open the connection\n"]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:04:38"],"user":["default_user"],"umph":[1543172678.5105],"ok":[false],"chunk":[37],"ex":[8],"e.ind":[0],"code":["contracts = read.dta13(\"contracts.dta\")\nshock.estimation = read.csv2(\"shock.estimation.csv\") # saved within Ex.4\n\nplanned_days = contracts$planned_days\nactual_days = contracts$actual_days\ndw_norm = contracts$dw_norm\npenalty = contracts$penalty\npenalty_norm = contracts$penalty_norm\n\nN = nrow(contracts) # total number of observed contract\nenforcement = contracts$enforcement # observed enf. for late contracts\noutcome = contracts$outcome2 # contract outcome (further info in the appendix)\n\n# contractors information set (variables for the matrix X)\nones = rep(1,N) # constant\nshock = shock.estimation[,]\nplanned_workrate = contracts$planned_workrate\ncontrval_norm = contracts$contrval_norm\nrain = contracts$rain\nsnow = contracts$snow\nbig_firm = contracts$big_firm\ninstate = contracts$instate\nfirm_backlog_norm = contracts$firm_backlog_norm\noverlap = contracts$overlap\nX=cBind(ones,shock,planned_workrate,contrval_norm,rain,snow,big_firm,instate,firm_backlog_norm,overlap)\n\n# additional and saved penalties (delta's)\ndelta.plus = (actual_days+1-pmax(actual_days,planned_days))*penalty\ndelta.minus = (actual_days-pmax(actual_days-1,planned_days))*penalty\n# For outcomes that do not apply, the result is equal to zero.\ndelta.plus[outcome==\"early\"] = 0\ndelta.minus[outcome==\"early\"|outcome==\"ontime\"] = 0\n\n############################### FUNCTIONS ###############################\nloglikelihood = function(coefs){\n  # Since we `log-likelihood`, we use the exp()-function for the parameters\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2]) # alpha should be negative -> slope of -c'(d)\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  ll = rep(0,N)\n  \n  # early contract\n  ll[outcome==\"early\"] = log(pnorm(rb.noenforce[outcome==\"early\"]) - pnorm(lb.noenforce[outcome==\"early\"]))\n  # late contract  \n  ll[outcome==\"late\"&enforce==0] = log(pnorm(rb.noenforce[outcome==\"late\"&enforce==0]) - pnorm(lb.noenforce[outcome==\"late\"&enforce==0])) + log(1-mean(enforce))\n  ll[outcome==\"late\"&enforce==1] = log(pnorm(rb.enforce[outcome==\"late\"&enforce==1]) - pnorm(lb.enforce[outcome==\"late\"&enforce==1])) + log(mean(enforce))\n# ontime contract - expected loglikelihood depending on the current enforcement choice\n  ll[outcome==\"ontime\"] = enforce[outcome==\"ontime\"]*log(pnorm(rb.enforce[outcome==\"ontime\"]) - pnorm(lb.enforce[outcome==\"ontime\"])) + (1-enforce[outcome==\"ontime\"])*log(pnorm(rb.noenforce[outcome==\"ontime\"]) - pnorm(lb.noenforce[outcome==\"ontime\"]))\n  LL = sum(ll)\n  return(LL)\n}\n\nenforce.posterior = function(coefs){\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2])\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # Bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  p.hat = mean(enforce)\n  posterior = enforce\n  \n  posterior[outcome==\"early\"] = p.hat\n  posterior[outcome==\"late\"] = enforcement[outcome==\"late\"]\n  \n  l.enforce = pnorm(rb.enforce) - pnorm(lb.enforce)\n  l.noenforce = pnorm(rb.noenforce) - pnorm(lb.noenforce)\n  \n  posterior[outcome==\"ontime\"] = p.hat*l.enforce[outcome==\"ontime\"]/(p.hat*l.enforce[outcome==\"ontime\"] + (1-p.hat)*l.noenforce[outcome==\"ontime\"])\n  return(posterior)\n}\n\ny.calc = function(alpha){\n  y = rep(0,N)\n  y[outcome == \"early\"] = -alpha*dw_norm[outcome == \"early\"]\n  y[outcome == \"ontime\"] = -alpha*dw_norm[outcome == \"ontime\"]\n  y[outcome == \"late\"] =  -alpha*dw_norm[outcome == \"late\"] + enforce[outcome == \"late\"]*penalty_norm[outcome == \"late\"]\n  return(y)\n}\n#########################################################################\n\n## STARTVALUE STEPS\nenforce = rep(1,N)\nenforce[outcome==\"late\"] = enforcement[outcome==\"late\"]\nenforce[outcome==\"early\"] = mean(enforce)\n\nn.start = 2000 # number of start values\nsigma.start = rnorm(n.start)*10 # N(0,100) distributed\nalpha.start = rnorm(n.start)*10 # N(0,100) distributed\n\n# evaluate every fval for the 1000 sigma and alpha possibilities\nfval.start = rep(0,n.start)\nfor (i in 1:n.start) {\n  fval.start[i] = loglikelihood(c(sigma.start[i],alpha.start[i]))\n}\n\n# identify the decent start values\nindex.decent = which(fval.start > -Inf)\nsigma.decent = sigma.start[index.decent]\nalpha.decent = alpha.start[index.decent]\nfval.decent = fval.start[index.decent]\n\n# coefs combination which generates the max fval -> maximum loglikelihood\nindex.max = which(fval.decent == max(fval.decent))\nfval.max = fval.decent[index.max]\ncoefs.max= c(sigma.decent[index.max],alpha.decent[index.max])\n\n############################### PLOT ###############################\n# plot of the decent values (I used the dist. between the several sigma\n# and alpha values on the x-axis and the corresponding fval on the y-axis\nplot(abs(sigma.decent-alpha.decent),fval.decent)\n# zooming into the maximum location\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch = 20,col=\"red\")\n####################################################################\n\nnm_opti = optim(coefs.max,loglikelihood,control=list(fnscale=-1))\ncoefs.star = nm_opti$par\nfval.star = nm_opti$value\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=3)\n####################################################################\ncoefs1 = coefs.star\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8) {\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs1)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs1,loglikelihood,control=list(fnscale=-1))\n  coefs1 = nm_opti$par\n  fval1 = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\n# include new points\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n####################################################################\n\n## FINAL EM-ALGORITHM\nalpha.hat = -exp(coefs1[2])\ny = y.calc(alpha.hat)\nbeta.start = solve(t(X)%*%X)%*%t(X)%*%y\ncoefs = c(coefs1,beta.start)\nnm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\ncoefs = nm_opti$par\nfval = nm_opti$value\ncoefs2=coefs\nfval2=fval\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n# include new points\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8){\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\n  coefs = nm_opti$par\n  fval = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=4,lwd=2)\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n# include new points\npoints(abs(coefs[1]-coefs[2]),fval,pch=21,col=\"black\",bg=\"#299a20\",cex=2)\n######################### RESULTS #########################\nestimates = c(P.hat.current,exp(coefs[1]),-exp(coefs[2]),coefs[3:length(coefs)])\nestimates"],"message":["evaluation error in \n  shock.estimation = read.csv2(\"shock.estimation.csv\")\n  Error in file(file, \"rt\"): cannot open the connection\n"]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:04:55"],"user":["default_user"],"umph":[1543172695.6018],"ok":[true],"chunk":[24],"ex":[6],"e.ind":[0],"code":["contracts = read.dta13(\"contracts.dta\")"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:05:02"],"user":["default_user"],"umph":[1543172702.8827],"ok":[true],"chunk":[25],"ex":[6],"e.ind":[0],"code":["# reg.hours = felm(... ~ ... + planned_workrate + contrval_norm + rain + snow + big_firm + instate + firm_backlog_norm + overlap | ... + district + primary_activity,data = contracts)\nreg.hours = felm(hw_norm ~ penalty_norm + planned_workrate + contrval_norm + rain + snow + big_firm + instate + firm_backlog_norm + overlap | year + district + primary_activity,data = contracts)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:05:05"],"user":["default_user"],"umph":[1543172705.4284],"ok":[true],"chunk":[26],"ex":[6],"e.ind":[0],"code":["# ... = residuals(...)\nshock = residuals(reg.hours)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:05:08"],"user":["default_user"],"umph":[1543172708.4945],"ok":[true],"chunk":[27],"ex":[6],"e.ind":[0],"code":["# reg.workrate = felm(... ~ ... + penalty_norm + planned_workrate + contrval_norm + rain + snow + big_firm + instate + firm_backlog_norm + overlap | year + district + primary_activity,data = contracts)\nreg.workrate = felm(actual_workrate ~ shock + penalty_norm + planned_workrate + contrval_norm + rain + snow + big_firm + instate + firm_backlog_norm + overlap | year + district + primary_activity,data = contracts)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:05:13"],"user":["default_user"],"umph":[1543172713.6154],"ok":[true],"chunk":[28],"ex":[6],"e.ind":[0],"code":["# stargazer(... , ... ,type=\"text\",align = T)\nstargazer(reg.hours,reg.workrate,type=\"text\",align = T)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:05:22"],"user":["default_user"],"umph":[1543172722.8971],"ok":[true],"chunk":[29],"ex":[6],"e.ind":[0],"code":["reg.MODEL.shock = lm(hw_norm ~ rep(1,466) + penalty_norm + planned_workrate + contrval_norm + rain + snow + big_firm + instate + firm_backlog_norm + overlap,data=contracts)\nshock.estimation = residuals(reg.MODEL.shock)\nwrite.csv2(shock.estimation,file = \"shock.estimation.csv\",row.names=F)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:06:00"],"user":["default_user"],"umph":[1543172760.8749],"ok":[true],"chunk":[37],"ex":[8],"e.ind":[0],"code":["contracts = read.dta13(\"contracts.dta\")\nshock.estimation = read.csv2(\"shock.estimation.csv\") # saved within Ex.4\n\nplanned_days = contracts$planned_days\nactual_days = contracts$actual_days\ndw_norm = contracts$dw_norm\npenalty = contracts$penalty\npenalty_norm = contracts$penalty_norm\n\nN = nrow(contracts) # total number of observed contract\nenforcement = contracts$enforcement # observed enf. for late contracts\noutcome = contracts$outcome2 # contract outcome (further info in the appendix)\n\n# contractors information set (variables for the matrix X)\nones = rep(1,N) # constant\nshock = shock.estimation[,]\nplanned_workrate = contracts$planned_workrate\ncontrval_norm = contracts$contrval_norm\nrain = contracts$rain\nsnow = contracts$snow\nbig_firm = contracts$big_firm\ninstate = contracts$instate\nfirm_backlog_norm = contracts$firm_backlog_norm\noverlap = contracts$overlap\nX=cBind(ones,shock,planned_workrate,contrval_norm,rain,snow,big_firm,instate,firm_backlog_norm,overlap)\n\n# additional and saved penalties (delta's)\ndelta.plus = (actual_days+1-pmax(actual_days,planned_days))*penalty\ndelta.minus = (actual_days-pmax(actual_days-1,planned_days))*penalty\n# For outcomes that do not apply, the result is equal to zero.\ndelta.plus[outcome==\"early\"] = 0\ndelta.minus[outcome==\"early\"|outcome==\"ontime\"] = 0\n\n############################### FUNCTIONS ###############################\nloglikelihood = function(coefs){\n  # Since we `log-likelihood`, we use the exp()-function for the parameters\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2]) # alpha should be negative -> slope of -c'(d)\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  ll = rep(0,N)\n  \n  # early contract\n  ll[outcome==\"early\"] = log(pnorm(rb.noenforce[outcome==\"early\"]) - pnorm(lb.noenforce[outcome==\"early\"]))\n  # late contract  \n  ll[outcome==\"late\"&enforce==0] = log(pnorm(rb.noenforce[outcome==\"late\"&enforce==0]) - pnorm(lb.noenforce[outcome==\"late\"&enforce==0])) + log(1-mean(enforce))\n  ll[outcome==\"late\"&enforce==1] = log(pnorm(rb.enforce[outcome==\"late\"&enforce==1]) - pnorm(lb.enforce[outcome==\"late\"&enforce==1])) + log(mean(enforce))\n# ontime contract - expected loglikelihood depending on the current enforcement choice\n  ll[outcome==\"ontime\"] = enforce[outcome==\"ontime\"]*log(pnorm(rb.enforce[outcome==\"ontime\"]) - pnorm(lb.enforce[outcome==\"ontime\"])) + (1-enforce[outcome==\"ontime\"])*log(pnorm(rb.noenforce[outcome==\"ontime\"]) - pnorm(lb.noenforce[outcome==\"ontime\"]))\n  LL = sum(ll)\n  return(LL)\n}\n\nenforce.posterior = function(coefs){\n  sigma = exp(coefs[1])\n  alpha = -exp(coefs[2])\n  \n  if (length(coefs) == 12){\n    beta = coefs[3:length(coefs)]\n  }\n  ### the  else part is only used for the determinition of start values ###\n  else {\n      y = y.calc(alpha)\n    beta = solve(t(X)%*%X)%*%t(X)%*%y\n  }\n  #########################################################################\n  \n  # Bounds on epsilon (already devided by sigma)\n  lb.enforce = (((delta.minus+alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  lb.noenforce = (((alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.enforce = (((delta.plus-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  rb.noenforce = (((-alpha/2)/planned_days - alpha*dw_norm) - X%*%beta)/sigma\n  \n  p.hat = mean(enforce)\n  posterior = enforce\n  \n  posterior[outcome==\"early\"] = p.hat\n  posterior[outcome==\"late\"] = enforcement[outcome==\"late\"]\n  \n  l.enforce = pnorm(rb.enforce) - pnorm(lb.enforce)\n  l.noenforce = pnorm(rb.noenforce) - pnorm(lb.noenforce)\n  \n  posterior[outcome==\"ontime\"] = p.hat*l.enforce[outcome==\"ontime\"]/(p.hat*l.enforce[outcome==\"ontime\"] + (1-p.hat)*l.noenforce[outcome==\"ontime\"])\n  return(posterior)\n}\n\ny.calc = function(alpha){\n  y = rep(0,N)\n  y[outcome == \"early\"] = -alpha*dw_norm[outcome == \"early\"]\n  y[outcome == \"ontime\"] = -alpha*dw_norm[outcome == \"ontime\"]\n  y[outcome == \"late\"] =  -alpha*dw_norm[outcome == \"late\"] + enforce[outcome == \"late\"]*penalty_norm[outcome == \"late\"]\n  return(y)\n}\n#########################################################################\n\n## STARTVALUE STEPS\nenforce = rep(1,N)\nenforce[outcome==\"late\"] = enforcement[outcome==\"late\"]\nenforce[outcome==\"early\"] = mean(enforce)\n\nn.start = 2000 # number of start values\nsigma.start = rnorm(n.start)*10 # N(0,100) distributed\nalpha.start = rnorm(n.start)*10 # N(0,100) distributed\n\n# evaluate every fval for the 1000 sigma and alpha possibilities\nfval.start = rep(0,n.start)\nfor (i in 1:n.start) {\n  fval.start[i] = loglikelihood(c(sigma.start[i],alpha.start[i]))\n}\n\n# identify the decent start values\nindex.decent = which(fval.start > -Inf)\nsigma.decent = sigma.start[index.decent]\nalpha.decent = alpha.start[index.decent]\nfval.decent = fval.start[index.decent]\n\n# coefs combination which generates the max fval -> maximum loglikelihood\nindex.max = which(fval.decent == max(fval.decent))\nfval.max = fval.decent[index.max]\ncoefs.max= c(sigma.decent[index.max],alpha.decent[index.max])\n\n############################### PLOT ###############################\n# plot of the decent values (I used the dist. between the several sigma\n# and alpha values on the x-axis and the corresponding fval on the y-axis\nplot(abs(sigma.decent-alpha.decent),fval.decent)\n# zooming into the maximum location\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch = 20,col=\"red\")\n####################################################################\n\nnm_opti = optim(coefs.max,loglikelihood,control=list(fnscale=-1))\ncoefs.star = nm_opti$par\nfval.star = nm_opti$value\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=3)\n####################################################################\ncoefs1 = coefs.star\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8) {\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs1)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs1,loglikelihood,control=list(fnscale=-1))\n  coefs1 = nm_opti$par\n  fval1 = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\n# include new points\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n####################################################################\n\n## FINAL EM-ALGORITHM\nalpha.hat = -exp(coefs1[2])\ny = y.calc(alpha.hat)\nbeta.start = solve(t(X)%*%X)%*%t(X)%*%y\ncoefs = c(coefs1,beta.start)\nnm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\ncoefs = nm_opti$par\nfval = nm_opti$value\ncoefs2=coefs\nfval2=fval\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=5,lwd=2)\n# include new points\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n\nP.hat.current = mean(enforce)\ndistance = 1\nwhile (distance > 1e-8){\n  P.hat.old = P.hat.current\n  enforce = enforce.posterior(coefs)\n  P.hat.current = mean(enforce)\n  nm_opti = optim(coefs,loglikelihood,control=list(fnscale=-1))\n  coefs = nm_opti$par\n  fval = nm_opti$value\n  distance = abs(P.hat.current-P.hat.old)\n}\n############################### PLOT ###############################\nplot(abs(sigma.decent-alpha.decent),fval.decent,xlim = c(abs(coefs.max[1]-coefs.max[2])-1,abs(coefs.max[1]-coefs.max[2])+1),ylim = c(fval.max-750,fval.max+750))\npoints(abs(coefs.max[1]-coefs.max[2]),fval.max,pch=20,col=\"red\")\npoints(abs(coefs.star[1]-coefs.star[2]),fval.star,pch=1,col=\"#299a20\",cex=6,lwd=2)\npoints(abs(coefs1[1]-coefs1[2]),fval1,pch=1,col=\"#299a20\",cex=4,lwd=2)\npoints(abs(coefs2[1]-coefs2[2]),fval2,pch=1,col=\"#299a20\",cex=3,lwd=2)\n# include new points\npoints(abs(coefs[1]-coefs[2]),fval,pch=21,col=\"black\",bg=\"#299a20\",cex=2)\n######################### RESULTS #########################\nestimates = c(P.hat.current,exp(coefs[1]),-exp(coefs[2]),coefs[3:length(coefs)])\nestimates"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:06:16"],"user":["default_user"],"umph":[1543172776.754],"ok":[true],"chunk":[38],"ex":[8],"e.ind":[0],"code":["# input the file 'estimates.RTutor.csv'\nestimates.next = read.csv2(\"estimates.RTutor.csv\")[,]\n\n# output the table\ncheck.error(estimates,estimates.next,planned_days,X)"],"message":[""]}
,
{"type":["check_chunk"],"time":["2018-11-25 20:06:41"],"user":["default_user"],"umph":[1543172801.928],"ok":[false],"chunk":[42],"ex":[10],"e.ind":[0],"code":["center = c(-93.37,46.55)\nserpentlake = c(-93.927,46.480)\nproject = serpentlake\nmap_subsample(center,serpentlake)"],"message":["evaluation error in \n  map_subsample(center, serpentlake)\n  Error in download.file(url, destfile = destfile, quiet = !messaging, mode = \"wb\"): cannot open URL 'https://maps.googleapis.com/maps/api/staticmap?center=46.55,-93.37&zoom=7&size=640x640&scale=2&maptype=roadmap&language=en-EN'\n"]}
,
